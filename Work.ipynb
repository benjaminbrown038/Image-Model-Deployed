{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 142 files [00:00, 599.50 files/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import splitfolders\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# split data into validation and training after created new folder.\n",
    "splitfolders.ratio('Images', output= 'Augmented_Images', seed = 1337, ratio = ((0.8,0.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 113 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training = ImageDataGenerator(rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest')\n",
    "\n",
    "training_directory = 'Augmented_Images/train/'\n",
    "# variable with batch size, from images in training dir\n",
    "training_batch_size = len(os.listdir(training_directory))\n",
    "training_data = training.flow_from_directory(training_directory,\n",
    "                                        target_size=(150,150),\n",
    "                                        batch_size = training_batch_size,\n",
    "                                        shuffle = False,\n",
    "                                        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "validation_directory = 'Augmented_Images/val/'\n",
    "validation_batch_size = len(os.listdir(validation_directory))\n",
    "validation_data = validation.flow_from_directory(validation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing how the Data is stored in the Keras Data object is important:\n",
    "- The training data is stored as one object containing the image and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = training_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Image:\n",
      "(2, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Image \n",
    "print(\"Size of Image:\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of array:\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "print(\"Size of array:\")\n",
    "print(x_train[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
